# ğŸ¤– AI Agent: Video â†’ Audio â†’ Transcript â†’ Summary using OpenAI

This project is a **Multimodal AI Agent** that can automatically extract **frames and audio from a video**, transcribe the audio into text, and generate a **summary** using **OpenAI GPT models** or **Google Gemini models**.

---

## ğŸ” Features

* ğŸ¥ Extract frames & audio from video
* ğŸ”Š Transcribe speech to text using Whisper or Google STT
* ğŸ§  Generate smart summaries using GPT-4o  
* ğŸ–¼ï¸ Analyze image frames (vision-language models)
* âš–ï¸ Switch between OpenAI and Gemini APIs easily
* ğŸ“š Educational and developer-friendly codebase

---

## ğŸ”§ Tech Stack

| Category          | Tools / Libraries                         |
| ----------------- | ----------------------------------------- |
| Programming       | Python                                    |
| Generative Models | OpenAI GPT-4o, Google Gemini Pro/Flash    |
| Audio Processing  | `moviepy`, `speechrecognition`, `whisper` |
| Image Processing  | `opencv-python`, `PIL`, `base64`          |
| LLM APIs          | `openai`, `google.generativeai`           |
| Optional UI       | `Chainlit`, `Gradio`, `Streamlit`         |

---

## ğŸš€ How It Works

1. **Upload/Specify a video file**
2. `process_video()` extracts audio and frames
3. `transcribe_audio()` converts audio to text
4. `summarize_transcription()` uses LLM to summarize the transcript
5. Optional: `analyze_frames()` sends images to GPT/Gemini for frame-wise analysis

---

## ğŸ‘ï¸ Use Cases

* ğŸ“ Lecture summarization tools
* ğŸ“… Meeting/podcast note generators
* ğŸŒ Multimodal chatbot agents
* ğŸ“° Video content summarizers

---

## ğŸ“ Folder Structure

```
AI_Agent/
â”‚
â”œâ”€â”€ main.py                # Core pipeline logic
â”œâ”€â”€ app.py                 # Chainlit/Streamlit app (optional)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # Project overview
â””â”€â”€ assets/                # Sample media files
```

---

## ğŸš§ Getting Started

### 1. Clone this repository

```bash
git clone https://github.com/your-username/ai-agent.git
cd ai-agent
```

### 2. Create a virtual environment

```bash
python -m venv venv
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Set up your API keys

* For **OpenAI**: Add your key as `OPENAI_API_KEY` in environment or script
* For **Gemini**: Configure using `genai.configure(api_key=...)`

---

## ğŸŒ Example Output

```bash
âœ… Extracted 12 frames
âœ… Audio saved at: ./your_video.mp3
ğŸ” Transcript:
"This is the transcription text..."

ğŸ“ˆ Summary:
"This video discusses how the speaker overcame their fear of public speaking..."
```

---

## ğŸ’¼ License

MIT License

---

## âœ¨ Contributing

PRs and improvements welcome! Feel free to fork and modify.

---

## ğŸ“ Credits

Built with â¤ï¸ using Python, OpenAI, and Gemini APIs.
